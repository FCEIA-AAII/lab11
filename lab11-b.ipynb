{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reglgYKsZYuZ"
      },
      "source": [
        "# Lab 11 B - Clasificacion de video con RNNs (CNN + LSTM)\n",
        "\n",
        "El objetivo de este laboratorio es entrenar un clasificador de videos utilizando una red neuronal recurrente (RNN). Para ello, se utilizará parte del dataset [UCF101](https://www.crcv.ucf.edu/data/UCF101.php) que contiene mas de 13000 videos clasificados en 101 clases. Para los fines del laboratorio se seleccionaron solo 3 clases del dataset (Basketball, Biking, Bowling).\n",
        "\n",
        "![](https://www.crcv.ucf.edu/data/UCF101/UCF101.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3WKnA_HarVV"
      },
      "source": [
        "## Preparación del entorno.\n",
        "\n",
        "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjRhXl0GarVV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_NAME = \"lab11\"\n",
        "if REPO_NAME not in os.getcwd():\n",
        "  if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/FCEIA-AAII/{REPO_NAME}.git\n",
        "  os.chdir(REPO_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z98IFGwXarVW"
      },
      "source": [
        "Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-16T12:28:51.777470Z",
          "iopub.status.busy": "2023-11-16T12:28:51.777245Z",
          "iopub.status.idle": "2023-11-16T12:28:54.138340Z",
          "shell.execute_reply": "2023-11-16T12:28:54.137637Z"
        },
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ__rWAFarVW"
      },
      "source": [
        "Establecer GPU por defecto en caso de estar disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WXQtezyIrn_",
        "outputId": "beac438a-27f3-4202-a9e3-cb54e6b3863a"
      },
      "outputs": [],
      "source": [
        "# Configurar para que TensorFlow utilice la GPU por defecto\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Configurar para que TensorFlow asigne memoria dinámicamente\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        # Especificar la GPU por defecto\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Manejar error\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrrRUZKHlE2q"
      },
      "source": [
        "## Preparacion del dataset\n",
        "\n",
        "En el interior de la carpeta dataset nos encontramos una carpeta por cada clase. En cada una de estas carpetas depositamos los videos representativos de su respectiva clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "w-OwwSRSkqgL",
        "outputId": "d57aec9b-d10d-4307-af3f-4e9198cff2a5"
      },
      "outputs": [],
      "source": [
        "data_dir = 'datasets/video-classification-dataset'\n",
        "classes = os.listdir(data_dir)\n",
        "num_classes = len(classes)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHAPeXucmgC9"
      },
      "source": [
        "Definimos los parametros de carga:\n",
        "\n",
        "![](images/segment.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFg-T8lYrG8J"
      },
      "outputs": [],
      "source": [
        "img_height, img_width = 50, 50\n",
        "segment_lenght = 10  # Número de frames a extraer por segmento\n",
        "segment_stride = 5  # Desplazamiento entre segmentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GBKaq4esSvT"
      },
      "source": [
        "Definimos una funcion para cargar el dataset a partir de los parametros mencionados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT-6elrrEaPs"
      },
      "outputs": [],
      "source": [
        "def load_video_classification_dataset(data_dir, img_height, img_width, segment_lenght, segment_stride):\n",
        "    X, y = [], []\n",
        "    for label, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for video_name in os.listdir(class_dir):\n",
        "            video_path = os.path.join(class_dir, video_name)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frames = []\n",
        "            success, frame = cap.read()\n",
        "            while success:\n",
        "                frame = cv2.resize(frame, (img_width, img_height))\n",
        "                frames.append(frame)\n",
        "                success, frame = cap.read()\n",
        "            cap.release()\n",
        "\n",
        "            # Extraer segmentos de frames\n",
        "            num_segments = (len(frames) - segment_lenght) // segment_stride + 1\n",
        "            for i in range(num_segments):\n",
        "                start = i * segment_stride\n",
        "                end = start + segment_lenght\n",
        "                segment = frames[start:end]\n",
        "                if len(segment) == segment_lenght:\n",
        "                    X.append(segment)\n",
        "                    y.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = to_categorical(y, num_classes)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HfSQoD7shPF"
      },
      "source": [
        "Cargamos el dataset y aplicamos shuffling y validation split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob8J6M4QsnsG"
      },
      "outputs": [],
      "source": [
        "# Cargar y preprocesar los datos\n",
        "X, y = load_video_classification_dataset(data_dir, img_height, img_width, segment_lenght, segment_stride)\n",
        "\n",
        "# Mezclar los datos antes de dividirlos en entrenamiento y validación\n",
        "indices = np.arange(len(X))\n",
        "np.random.shuffle(indices)\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6bOgm1vtJ4i"
      },
      "source": [
        "## Arquitectura del modelo y entrenamiento\n",
        "\n",
        "La arquitectura que se presenta a continuacion podemos descomponerla en 3 partes:\n",
        "\n",
        "\n",
        "1.   Capas convolucionales: Extraccion de caracteristicas espaciales.\n",
        "2.   Capa recurrente: Extraccion de caracteristicas temporales.\n",
        "3.   Capas de salida: Juntan las caracteristicas 1, 2 y producen la prediccion de clase.\n",
        "\n",
        "\n",
        "\n",
        "Nota: La capa **TimeDistributed** se usa para aplicar las capas convolucionales a cada frame del video de forma independiente antes de pasar las características extraídas a la capa LSTM, que luego puede capturar las dependencias temporales entre estos frames.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqGyuUXxFFLm",
        "outputId": "a1be717f-9ffa-4bc7-8adb-a940bc2629cc"
      },
      "outputs": [],
      "source": [
        "model_cnlst = Sequential()\n",
        "# Capas convolucionales\n",
        "model_cnlst.add(TimeDistributed(Conv2D(64, (3, 3), strides=(1,1),activation='relu'), input_shape=(segment_lenght, img_height, img_width, 3)))\n",
        "model_cnlst.add(TimeDistributed(Conv2D(32, (3, 3), strides=(1,1),activation='relu')))\n",
        "model_cnlst.add(TimeDistributed(MaxPooling2D(2,2)))\n",
        "model_cnlst.add(TimeDistributed(Conv2D(32, (3, 3), strides=(1,1),activation='relu')))\n",
        "model_cnlst.add(TimeDistributed(Conv2D(16, (3, 3), strides=(1,1),activation='relu')))\n",
        "model_cnlst.add(TimeDistributed(MaxPooling2D(2,2)))\n",
        "model_cnlst.add(TimeDistributed(BatchNormalization()))\n",
        "model_cnlst.add(TimeDistributed(Flatten()))\n",
        "model_cnlst.add(Dropout(0.5))\n",
        "# Capa recurrente\n",
        "model_cnlst.add(LSTM(32, return_sequences=False, dropout=0.5))\n",
        "# Capas de salida\n",
        "model_cnlst.add(Dense(64, activation='relu'))\n",
        "model_cnlst.add(Dense(32, activation='relu'))\n",
        "model_cnlst.add(Dropout(0.5))\n",
        "model_cnlst.add(Dense(num_classes, activation='softmax'))\n",
        "# Resumen del modelo\n",
        "model_cnlst.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9oul7YCwLMv"
      },
      "source": [
        "Corremos el entrenamiento con early stopping y model checkpoints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kz4_aEMFUGX",
        "outputId": "8e15a500-d303-4937-fae8-0e660c3082ed"
      },
      "outputs": [],
      "source": [
        "# Compilar el modelo\n",
        "model_cnlst.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Definir callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Entrenar el modelo con callbacks\n",
        "history = model_cnlst.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), batch_size=8,\n",
        "                          callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluación del modelo en el conjunto de validación\n",
        "val_loss, val_accuracy = model_cnlst.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "225bi8SYwTGH"
      },
      "source": [
        "Analizamos los resultamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "BxaYOrimFVWN",
        "outputId": "33ef31d5-45b6-4ccc-d723-3fe36b03c69a"
      },
      "outputs": [],
      "source": [
        "# Visualización de la precisión y pérdida durante el entrenamiento\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
